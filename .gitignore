#1
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline
#2
dataset=pd.read_csv('train.csv')
dataset.head()
#3
dataset.info()
#4
X=dataset.drop('price_range',axis=1)
#5
y=dataset['price_range']
#6
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)
#7
from sklearn.linear_model import LinearRegression
lm = LinearRegression()
lm.fit(X_train,y_train)
#8
lm.score(X_test,y_test)
#9
from sklearn.metrics import mean_squared_error, r2_score

pred = lm.predict(X_test)

# Evaluate using regression metrics
mse = mean_squared_error(y_test, pred)
r2 = r2_score(y_test, pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
#10
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=10)
knn.fit(X_train,y_train)
knn.score(X_test,y_test)
#11
error_rate = []
for i in range(1,20):

    knn = KNeighborsClassifier(n_neighbors=i)
    knn.fit(X_train,y_train)
    pred_i = knn.predict(X_test)
    error_rate.append(np.mean(pred_i != y_test))
#12
plt.figure(figsize=(10,6))
plt.plot(range(1,20),error_rate,color='black', linestyle='dashed', marker='o',
         markerfacecolor='red', markersize=15)
plt.title('Error Rate vs. K Value')
plt.xlabel('K')
plt.ylabel('Error Rate')
#13
from sklearn.linear_model import LogisticRegression
logmodel = LogisticRegression()
logmodel.fit(X_train,y_train)
#14
logmodel.score(X_test,y_test)
#15
data_test=pd.read_csv('test.csv')
data_test.head()
#16
data_test=data_test.drop('id',axis=1)
data_test.head()
#17
predicted_price=logmodel.predict(data_test)
#18
predicted_price
#19
data_test['price_range']=predicted_price
data_test.head()
